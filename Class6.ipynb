{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing with Sklearn using Standard and Minmax scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Scaling is a data preprocessing step for numerical features. Many machine learning algorithms like Gradient descent methods, KNN algorithm, linear and logistic regression, etc. require data scaling to produce good results. Various scalers are defined for this purpose. This article concentrates on Standard Scaler and Min-Max scaler. The task here is to discuss what they mean and how they are implemented using in-built functions that come with this package.\n",
    "\n",
    "Apart from supporting library functions other functions that will be used to achieve the functionality are:<br>\n",
    "\n",
    "* The **fit(data)** method is used to compute the mean and std dev for a given feature so that it can be used further for scaling.\n",
    "* The **transform(data)** method is used to perform scaling using mean and std dev calculated using the .fit() method.\n",
    "* The **fit_transform()** method does both fit and transform.\n",
    "Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                    Standard Scaler\n",
    "Standard Scaler helps to get standardized distribution, with a zero mean and standard deviation of one (unit variance). It standardizes features by subtracting the mean value from the feature and then dividing the result by feature standard deviation. \n",
    "\n",
    "The standard scaling is calculated as: \n",
    "\n",
    "z = (x - u) / s<br>\n",
    "Where,\n",
    "\n",
    "z is scaled data.\n",
    "x is to be scaled data.\n",
    "u is the mean of the training samples\n",
    "s is the standard deviation of the training samples.\n",
    "Sklearn preprocessing supports StandardScaler() method to achieve this directly in merely 2-3 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach:\n",
    "* Import module\n",
    "* Create data\n",
    "* Compute required values\n",
    "* Print Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97596444 -1.61155897]\n",
      " [-0.66776515  0.08481889]\n",
      " [-1.28416374  1.10264561]\n",
      " [ 0.97596444  0.42409446]]\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#create data\n",
    "data = [[11, 2], [3, 7], [0, 10], [11, 8]]\n",
    "\n",
    "#compute required values\n",
    "scaler = StandardScaler()\n",
    "model = scaler.fit(data)\n",
    "scaled_data = model.transform(data)\n",
    "\n",
    "#print the data\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax Scaler\n",
    "There is another way of data scaling, where the minimum of feature is made equal to zero and the maximum of feature equal to one. MinMax Scaler shrinks the data within the given range, usually of 0 to 1. It transforms data by scaling features to a given range. It scales the values to a specific value range without changing the shape of the original distribution.\n",
    "\n",
    "The MinMax scaling is done using:<br>\n",
    "\n",
    "x_std = (x – x.min(axis=0)) / (x.max(axis=0) – x.min(axis=0))<br>\n",
    "\n",
    "x_scaled = x_std * (max – min) + min<br>\n",
    "\n",
    "Where,<br>\n",
    "\n",
    "min, max = feature_range<br>\n",
    "x.min(axis=0) : Minimum feature value<br>\n",
    "x.max(axis=0):Maximum feature value<br>\n",
    "Sklearn preprocessing defines MinMaxScaler() method to achieve this.<be>\n",
    "\n",
    "**Syntax**: class sklearn.preprocessing.MinMaxScaler(feature_range=0, 1, *, copy=True, clip=False)<br>\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "feature_range: Desired range of scaled data. The default range for the feature returned by MinMaxScaler is  0 to 1. The range is provided in tuple form as (min,max).\n",
    "copy: If False, inplace scaling is done. If True , copy is created instead of inplace scaling.\n",
    "**clip**: If True, scaled data is clipped to provided feature range.\n",
    "***Approach***:\n",
    "\n",
    "* Import module\n",
    "* Create data\n",
    "* Scale data\n",
    "* print scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.        ]\n",
      " [0.27272727 0.625     ]\n",
      " [0.         1.        ]\n",
      " [1.         0.75      ]]\n"
     ]
    }
   ],
   "source": [
    "#import module\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#create data\n",
    "data = [[11, 2], [3, 7], [0, 10], [11, 8]]\n",
    "\n",
    "#scale features\n",
    "scaler = MinMaxScaler()\n",
    "model = scaler.fit(data)\n",
    "scaled_data = model.transform(data)\n",
    "\n",
    "#print(scaled features)\n",
    "print(scaled_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
